{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Calibración de Confianza\n",
        "\n",
        "Este cuaderno permite:\n",
        "\n",
        "1. Cargar datasets generados con `scripts/confidence/build_dataset.py`.\n",
        "2. Entrenar múltiples calibradores (Platt / Isotónico) por régimen.\n",
        "3. Visualizar curvas de confiabilidad y métricas (Brier / ECE).\n",
        "4. Exportar los modelos aprobados como artefactos versionados.\n",
        "\n",
        "> Ejecuta siempre este notebook con la misma versión de código y dataset para garantizar reproducibilidad.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import brier_score_loss\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "REPO_ROOT = Path.cwd().parents[0] if Path.cwd().name == \"confidence\" else Path.cwd()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_path = REPO_ROOT / \"artifacts\" / \"confidence\" / \"datasets\" / \"<reemplaza_con_dataset>\"\n",
        "dataset_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = pd.read_parquet(dataset_path, engine=\"pyarrow\")\n",
        "dataset.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from app.confidence.calibrator import IsotonicCalibrator, PlattCalibrator, expected_calibration_error\n",
        "\n",
        "results = {}\n",
        "for regime, df_regime in dataset.groupby(dataset[\"market_regime\"].str.lower()):\n",
        "    if len(df_regime) < 200:\n",
        "        continue\n",
        "    X = df_regime[\"confidence_norm\"].to_numpy().reshape(-1, 1)\n",
        "    y = df_regime[\"hit\"].astype(int).to_numpy()\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "    calibrators = {\n",
        "        \"platt\": PlattCalibrator(),\n",
        "        \"isotonic\": IsotonicCalibrator(),\n",
        "    }\n",
        "    regime_results = {}\n",
        "    for name, calibrator in calibrators.items():\n",
        "        calibrator.fit(X_train, y_train)\n",
        "        prob = np.clip(calibrator.predict_proba(X_test), 0.0, 1.0)\n",
        "        brier = brier_score_loss(y_test, prob)\n",
        "        ece = expected_calibration_error(y_test, prob)\n",
        "        regime_results[name] = {\n",
        "            \"model\": calibrator,\n",
        "            \"brier\": brier,\n",
        "            \"ece\": ece,\n",
        "            \"y_test\": y_test,\n",
        "            \"prob\": prob,\n",
        "        }\n",
        "    results[regime] = regime_results\n",
        "\n",
        "results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_reliability(regime: str, calibrator_name: str) -> None:\n",
        "    payload = results[regime][calibrator_name]\n",
        "    y_true = payload[\"y_test\"]\n",
        "    y_prob = payload[\"prob\"]\n",
        "    bins = np.linspace(0.0, 1.0, 11)\n",
        "    accuracies = []\n",
        "    confidences = []\n",
        "    for i in range(len(bins) - 1):\n",
        "        mask = (y_prob >= bins[i]) & (y_prob < bins[i + 1])\n",
        "        if mask.any():\n",
        "            accuracies.append(np.mean(y_true[mask]))\n",
        "            confidences.append(np.mean(y_prob[mask]))\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
        "    plt.plot(confidences, accuracies, marker=\"o\")\n",
        "    plt.title(f\"Reliability Curve | {regime} | {calibrator_name}\")\n",
        "    plt.xlabel(\"Confidence\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "plot_reliability(regime=list(results.keys())[0], calibrator_name=\"platt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generar reporte HTML completo\n",
        "from datetime import datetime\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')  # Para generar sin display\n",
        "\n",
        "html_report = f\"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>Confidence Calibration Report - {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} UTC</title>\n",
        "    <style>\n",
        "        body {{ font-family: Arial, sans-serif; margin: 20px; }}\n",
        "        h1 {{ color: #333; }}\n",
        "        h2 {{ color: #666; margin-top: 30px; }}\n",
        "        table {{ border-collapse: collapse; width: 100%; margin: 20px 0; }}\n",
        "        th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}\n",
        "        th {{ background-color: #f2f2f2; }}\n",
        "        .metric {{ font-weight: bold; }}\n",
        "        .good {{ color: green; }}\n",
        "        .warning {{ color: orange; }}\n",
        "        .bad {{ color: red; }}\n",
        "        img {{ max-width: 100%; height: auto; margin: 10px 0; }}\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <h1>Confidence Calibration Validation Report</h1>\n",
        "    <p><strong>Generated:</strong> {datetime.utcnow().isoformat()} UTC</p>\n",
        "    <p><strong>Dataset:</strong> {str(dataset_path)}</p>\n",
        "    \n",
        "    <h2>Summary by Regime</h2>\n",
        "    <table>\n",
        "        <tr>\n",
        "            <th>Regime</th>\n",
        "            <th>Calibrator</th>\n",
        "            <th>Brier Score</th>\n",
        "            <th>ECE</th>\n",
        "            <th>Test Samples</th>\n",
        "            <th>Status</th>\n",
        "        </tr>\n",
        "\"\"\"\n",
        "\n",
        "for regime, candidates in results.items():\n",
        "    best = min(candidates.items(), key=lambda kv: kv[1][\"ece\"])\n",
        "    name, payload = best\n",
        "    brier = payload[\"brier\"]\n",
        "    ece = payload[\"ece\"]\n",
        "    n_samples = len(payload[\"y_test\"])\n",
        "    \n",
        "    status_class = \"good\" if ece < 0.05 and brier < 0.08 else (\"warning\" if ece < 0.10 else \"bad\")\n",
        "    status_text = \"✓ Good\" if status_class == \"good\" else (\"⚠ Warning\" if status_class == \"warning\" else \"✗ Poor\")\n",
        "    \n",
        "    html_report += f\"\"\"\n",
        "        <tr>\n",
        "            <td>{regime}</td>\n",
        "            <td>{name}</td>\n",
        "            <td class=\"metric\">{brier:.4f}</td>\n",
        "            <td class=\"metric\">{ece:.4f}</td>\n",
        "            <td>{n_samples}</td>\n",
        "            <td class=\"{status_class}\">{status_text}</td>\n",
        "        </tr>\n",
        "    \"\"\"\n",
        "\n",
        "html_report += \"\"\"\n",
        "    </table>\n",
        "    \n",
        "    <h2>Reliability Curves</h2>\n",
        "\"\"\"\n",
        "\n",
        "# Guardar imágenes de reliability curves\n",
        "import base64\n",
        "from io import BytesIO\n",
        "\n",
        "for regime, candidates in results.items():\n",
        "    best = min(candidates.items(), key=lambda kv: kv[1][\"ece\"])\n",
        "    name, payload = best\n",
        "    y_true = payload[\"y_test\"]\n",
        "    y_prob = payload[\"prob\"]\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    bins = np.linspace(0.0, 1.0, 11)\n",
        "    accuracies = []\n",
        "    confidences = []\n",
        "    for i in range(len(bins) - 1):\n",
        "        mask = (y_prob >= bins[i]) & (y_prob < bins[i + 1])\n",
        "        if mask.any():\n",
        "            accuracies.append(np.mean(y_true[mask]))\n",
        "            confidences.append(np.mean(y_prob[mask]))\n",
        "    \n",
        "    ax.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\", label=\"Perfect Calibration\")\n",
        "    ax.plot(confidences, accuracies, marker=\"o\", label=f\"{name} (ECE={payload['ece']:.4f})\")\n",
        "    ax.set_xlabel(\"Confidence\")\n",
        "    ax.set_ylabel(\"Accuracy\")\n",
        "    ax.set_title(f\"Reliability Curve | {regime} | {name}\")\n",
        "    ax.grid(True)\n",
        "    ax.legend()\n",
        "    \n",
        "    # Convertir a base64\n",
        "    buf = BytesIO()\n",
        "    fig.savefig(buf, format='png', dpi=150, bbox_inches='tight')\n",
        "    buf.seek(0)\n",
        "    img_base64 = base64.b64encode(buf.read()).decode('utf-8')\n",
        "    plt.close(fig)\n",
        "    \n",
        "    html_report += f\"\"\"\n",
        "    <h3>{regime} - {name}</h3>\n",
        "    <img src=\"data:image/png;base64,{img_base64}\" alt=\"Reliability Curve {regime} {name}\" />\n",
        "    \"\"\"\n",
        "\n",
        "html_report += \"\"\"\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "# Guardar reporte\n",
        "report_path = REPO_ROOT / \"artifacts\" / \"confidence\" / f\"validation_report_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.html\"\n",
        "report_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "report_path.write_text(html_report, encoding='utf-8')\n",
        "print(f\"Reporte HTML guardado en: {report_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "artifacts_root = REPO_ROOT / \"artifacts\" / \"confidence\"\n",
        "artifacts_root.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "for regime, candidates in results.items():\n",
        "    best = min(candidates.items(), key=lambda kv: kv[1][\"ece\"])\n",
        "    name, payload = best\n",
        "    metadata = {\n",
        "        \"regime\": regime,\n",
        "        \"calibrator_type\": name,\n",
        "        \"brier\": float(payload[\"brier\"]),\n",
        "        \"ece\": float(payload[\"ece\"]),\n",
        "        \"created_at\": datetime.utcnow().isoformat(),\n",
        "    }\n",
        "    target_dir = artifacts_root / regime\n",
        "    target_dir.mkdir(parents=True, exist_ok=True)\n",
        "    joblib.dump({\"calibrator\": payload[\"model\"], \"metadata\": metadata}, target_dir / \"calibrator.pkl\")\n",
        "    (target_dir / \"metadata.json\").write_text(json.dumps(metadata, indent=2), encoding=\"utf-8\")\n",
        "\n",
        "print(\"Artefactos actualizados.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
